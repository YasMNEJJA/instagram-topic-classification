{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Impressions</th>\n",
       "      <th>From Home</th>\n",
       "      <th>From Hashtags</th>\n",
       "      <th>From Explore</th>\n",
       "      <th>From Other</th>\n",
       "      <th>Saves</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Shares</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Profile Visits</th>\n",
       "      <th>Follows</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3920</td>\n",
       "      <td>2586</td>\n",
       "      <td>1028</td>\n",
       "      <td>619</td>\n",
       "      <td>56</td>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>Here are some of the most important data visua...</td>\n",
       "      <td>#finance #money #business #investing #investme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5394</td>\n",
       "      <td>2727</td>\n",
       "      <td>1838</td>\n",
       "      <td>1174</td>\n",
       "      <td>78</td>\n",
       "      <td>194</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>224</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>Here are some of the best data science project...</td>\n",
       "      <td>#healthcare #health #covid #data #datascience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4021</td>\n",
       "      <td>2085</td>\n",
       "      <td>1188</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "      <td>Learn how to train a machine learning model an...</td>\n",
       "      <td>#data #datascience #dataanalysis #dataanalytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4528</td>\n",
       "      <td>2700</td>\n",
       "      <td>621</td>\n",
       "      <td>932</td>\n",
       "      <td>73</td>\n",
       "      <td>172</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>Heres how you can write a Python program to d...</td>\n",
       "      <td>#python #pythonprogramming #pythonprojects #py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2518</td>\n",
       "      <td>1704</td>\n",
       "      <td>255</td>\n",
       "      <td>279</td>\n",
       "      <td>37</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Plotting annotations while visualizing your da...</td>\n",
       "      <td>#datavisualization #datascience #data #dataana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Impressions  From Home  From Hashtags  From Explore  From Other  Saves  \\\n",
       "0         3920       2586           1028           619          56     98   \n",
       "1         5394       2727           1838          1174          78    194   \n",
       "2         4021       2085           1188             0         533     41   \n",
       "3         4528       2700            621           932          73    172   \n",
       "4         2518       1704            255           279          37     96   \n",
       "\n",
       "   Comments  Shares  Likes  Profile Visits  Follows  \\\n",
       "0         9       5    162              35        2   \n",
       "1         7      14    224              48       10   \n",
       "2        11       1    131              62       12   \n",
       "3        10       7    213              23        8   \n",
       "4         5       4    123               8        0   \n",
       "\n",
       "                                             Caption  \\\n",
       "0  Here are some of the most important data visua...   \n",
       "1  Here are some of the best data science project...   \n",
       "2  Learn how to train a machine learning model an...   \n",
       "3  Heres how you can write a Python program to d...   \n",
       "4  Plotting annotations while visualizing your da...   \n",
       "\n",
       "                                            Hashtags  \n",
       "0  #finance #money #business #investing #investme...  \n",
       "1  #healthcare #health #covid #data #datascience ...  \n",
       "2  #data #datascience #dataanalysis #dataanalytic...  \n",
       "3  #python #pythonprogramming #pythonprojects #py...  \n",
       "4  #datavisualization #datascience #data #dataana...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/Instagram data.csv\", encoding=\"latin1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are some of the most important data visualizations that every Financial Data Analyst/Scientist should know.#finance #money #business #investing #investment #trading #stockmarket #data #datascience #dataanalysis #dataanalytics #datascientist #machinelearning #python #pythonprogramming #pythonprojects #pythoncode #artificialintelligence #ai #dataanalyst #amankharwal #thecleverprogrammer'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenate captions and hashtags in one column\n",
    "posts_text = df['Caption']+ df['Hashtags'].astype(str)\n",
    "posts_text = posts_text.str.replace('\\xa0', ' ', regex=True)\n",
    "posts_text[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['instagram_post'] = posts_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yasmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.084*\"datum\" + 0.043*\"science\" + 0.036*\"project\" + 0.028*\"datascience\" + 0.027*\"ai\" + 0.025*\"amankharwal\" + 0.025*\"topic\" + 0.024*\"dataanalytic\" + 0.024*\"dataanalysis\" + 0.024*\"machinelearne\"')\n",
      "(1, '0.076*\"python\" + 0.035*\"pythoncode\" + 0.033*\"use\" + 0.032*\"programming\" + 0.032*\"amankharwal\" + 0.024*\"pythonproject\" + 0.021*\"code\" + 0.018*\"language\" + 0.017*\"computerscience\" + 0.016*\"pythonlearne\"')\n",
      "(2, '0.112*\"datum\" + 0.049*\"dataanalysis\" + 0.049*\"dataanalytic\" + 0.048*\"ai\" + 0.048*\"datascientist\" + 0.048*\"science\" + 0.047*\"datascience\" + 0.045*\"deeplearne\" + 0.044*\"amankharwal\" + 0.042*\"machinelearning\"')\n",
      "(3, '0.049*\"python\" + 0.042*\"machine\" + 0.041*\"algorithm\" + 0.034*\"learning\" + 0.033*\"learn\" + 0.029*\"pythonproject\" + 0.029*\"pythoncode\" + 0.026*\"amankharwal\" + 0.024*\"use\" + 0.023*\"dataanalytic\"')\n",
      "(4, '0.054*\"python\" + 0.040*\"pythoncode\" + 0.034*\"pythonproject\" + 0.032*\"learn\" + 0.031*\"ukraine\" + 0.026*\"use\" + 0.025*\"sentiment\" + 0.025*\"amankharwal\" + 0.021*\"otp\" + 0.019*\"russia\"')\n",
      "\n",
      "Coherence Score:  0.3967047168696512\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Load data\n",
    "data = df\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    text = re.sub('\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub('\\S*@\\S*\\s?', '', text)  # Remove emails\n",
    "    text = re.sub('\\'', '', text)  # Remove apostrophes\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)  # Remove non-alphabet characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "data['instagram_post_cleaned'] = data['instagram_post'].apply(preprocess_text)  \n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "def tokenize(text):\n",
    "    tokens = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "data['tokens'] = data['instagram_post_cleaned'].apply(tokenize)\n",
    "\n",
    "# Lemmatization using spaCy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "def lemmatize(tokens):\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "data['lemmas'] = data['tokens'].apply(lemmatize)\n",
    "\n",
    "# Create dictionary and corpus\n",
    "id2word = corpora.Dictionary(data['lemmas'])\n",
    "texts = data['lemmas']\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=5, \n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True)\n",
    "\n",
    "# Print the topics\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "# Compute coherence score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data['lemmas'], dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.091*\"datum\" + 0.043*\"science\" + 0.036*\"ai\" + 0.036*\"datascience\" + 0.034*\"amankharwal\" + 0.033*\"dataanalysis\" + 0.033*\"datascientist\" + 0.033*\"dataanalytic\" + 0.029*\"deeplearne\" + 0.026*\"project\"'),\n",
       " (1,\n",
       "  '0.075*\"python\" + 0.046*\"pythoncode\" + 0.036*\"pythonproject\" + 0.032*\"amankharwal\" + 0.030*\"use\" + 0.022*\"programming\" + 0.021*\"pythonlearne\" + 0.021*\"pythondeveloper\" + 0.019*\"code\" + 0.017*\"language\"'),\n",
       " (2,\n",
       "  '0.038*\"algorithm\" + 0.037*\"python\" + 0.035*\"machine\" + 0.026*\"learn\" + 0.024*\"use\" + 0.024*\"dataanalytic\" + 0.023*\"learning\" + 0.023*\"datum\" + 0.023*\"deeplearning\" + 0.023*\"datascientist\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
